{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8335b29e",
   "metadata": {},
   "source": [
    "01_user_activity_scale.pdf：每用户 stays 数分布（log-log）+ 每用户时间跨度（log-log）\n",
    "\n",
    "02_user_entropy.pdf：user visit entropy + user conditional transition entropy\n",
    "\n",
    "03_global_cond_entropy_by_grid.pdf：全局按 current grid 的 H(next|curr) 分布\n",
    "\n",
    "04_topk_visit_ratio.pdf：Top-1/3/5 visit ratio across users（boxplot）\n",
    "\n",
    "05_routine_vs_tail.pdf：每用户 routine stay fraction / routine next fraction 分布\n",
    "\n",
    "06_global_routine_fractions.pdf：全局均值条形图\n",
    "\n",
    "07_time_uncertainty.pdf：stay duration + inter-stay gap（log-log）\n",
    "\n",
    "08_context_availability.pdf：fuzzy/precise/both 的出现比例\n",
    "\n",
    "09_precise_alignment.pdf：precise context 的 step distance 分布 + 匹配率\n",
    "\n",
    "10_fuzzy_alignment.pdf：fuzzy context 的 step distance 分布 + sigma 解析分布（若可解析）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3385a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[User Activity Summary]\n",
      "  n_users: 168\n",
      "  n_stays: 27914\n",
      "  n_transitions: 27746\n",
      "  stays_per_user_mean: 166.1547619047619\n",
      "  stays_per_user_median: 46.0\n",
      "  stays_per_user_std: 328.4789476041115\n",
      "  stays_per_user_IQR: 146.0\n",
      "  span_days_mean: 182.44300581459436\n",
      "  span_days_median: 74.4909201388889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_12932\\2149088866.py:59: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  bp = ax.boxplot(data_list, labels=labels, patch_artist=True, showfliers=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Context Availability]\n",
      "  fuzzy:   0.4151\n",
      "  precise: 0.4151\n",
      "  both:    0.4151\n",
      "\n",
      "All figures saved to: d:\\codeSpace\\TrajectoryFeatureGeneration\\Pictures\\GeoLife\n"
     ]
    }
   ],
   "source": [
    "# dataset_stats.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Dataset statistics + visualization for GeoLife_all.csv\n",
    "\n",
    "Implements:\n",
    "1) User activity & trajectory scale distribution\n",
    "2) Transition entropy / uncertainty metrics\n",
    "3) Routine vs Aperiodic quantification\n",
    "4) Time uncertainty distributions\n",
    "5) Context availability\n",
    "6) Context availability & alignment (precise/fuzzy)\n",
    "\n",
    "Outputs figures to ./figures/\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities\n",
    "# -----------------------------\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def entropy_from_counts(counts: np.ndarray, base: float = 2.0) -> float:\n",
    "    \"\"\"Entropy from counts (non-negative).\"\"\"\n",
    "    counts = counts.astype(float)\n",
    "    s = counts.sum()\n",
    "    if s <= 0:\n",
    "        return 0.0\n",
    "    p = counts / s\n",
    "    p = p[p > 0]\n",
    "    return float(-(p * (np.log(p) / np.log(base))).sum())\n",
    "\n",
    "\n",
    "def nice_hist(ax, x, bins=50, logx=False, logy=False, title=\"\", xlabel=\"\", ylabel=\"Count\",\n",
    "              color=None, alpha=0.85):\n",
    "    x = np.asarray(x)\n",
    "    x = x[np.isfinite(x)]\n",
    "    ax.hist(x, bins=bins, color=color, alpha=alpha, edgecolor=\"white\", linewidth=0.6)\n",
    "    if logx:\n",
    "        ax.set_xscale(\"log\")\n",
    "    if logy:\n",
    "        ax.set_yscale(\"log\")\n",
    "    ax.set_title(title, pad=10)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.6, alpha=0.35)\n",
    "\n",
    "\n",
    "def nice_box(ax, data_list, labels, title=\"\", ylabel=\"\", colors=None):\n",
    "    bp = ax.boxplot(data_list, labels=labels, patch_artist=True, showfliers=False)\n",
    "    if colors is None:\n",
    "        colors = [None] * len(data_list)\n",
    "    for patch, c in zip(bp[\"boxes\"], colors):\n",
    "        if c is not None:\n",
    "            patch.set_facecolor(c)\n",
    "        patch.set_alpha(0.85)\n",
    "        patch.set_edgecolor(\"#333333\")\n",
    "        patch.set_linewidth(1.0)\n",
    "    for k in [\"whiskers\", \"caps\", \"medians\"]:\n",
    "        for line in bp[k]:\n",
    "            line.set_color(\"#333333\")\n",
    "            line.set_linewidth(1.0)\n",
    "    ax.set_title(title, pad=10)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.6, alpha=0.35)\n",
    "\n",
    "\n",
    "def parse_context_precise(text: str):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    'User 0 will move from grid 14808 to grid 14800, at 2008-10-26 15:03:47.'\n",
    "    Returns (to_grid:int, t:Timestamp) or (None, None)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return None, None\n",
    "    m_grid = re.search(r\"to grid\\s+(\\d+)\", text)\n",
    "    m_time = re.search(r\"at\\s+(\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2})\", text)\n",
    "    if not m_grid or not m_time:\n",
    "        return None, None\n",
    "    to_grid = int(m_grid.group(1))\n",
    "    t = pd.to_datetime(m_time.group(1), errors=\"coerce\")\n",
    "    if pd.isna(t):\n",
    "        return None, None\n",
    "    return to_grid, t\n",
    "\n",
    "\n",
    "def parse_context_fuzzy(text: str):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    'User 0 will move from grid 14808 to grid 14800, arriving around in about 3 days, on 2008-10-26.'\n",
    "    Returns (to_grid:int, date:Timestamp normalized to date, sigma_minutes:float or None)\n",
    "    - sigma_minutes extracted from \"in about X (days|hours|mins)\" if present\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return None, None, None\n",
    "    m_grid = re.search(r\"to grid\\s+(\\d+)\", text)\n",
    "    m_date = re.search(r\"on\\s+(\\d{4}-\\d{2}-\\d{2})\", text)\n",
    "    if not m_grid or not m_date:\n",
    "        return None, None, None\n",
    "    to_grid = int(m_grid.group(1))\n",
    "    date = pd.to_datetime(m_date.group(1), errors=\"coerce\")\n",
    "    if pd.isna(date):\n",
    "        return None, None, None\n",
    "    date = date.normalize()\n",
    "\n",
    "    sigma_minutes = None\n",
    "    m_sigma = re.search(r\"in about\\s+(\\d+)\\s*(day|days|hour|hours|min|mins|minute|minutes)\", text)\n",
    "    if m_sigma:\n",
    "        val = float(m_sigma.group(1))\n",
    "        unit = m_sigma.group(2)\n",
    "        if unit.startswith(\"day\"):\n",
    "            sigma_minutes = val * 24 * 60\n",
    "        elif unit.startswith(\"hour\"):\n",
    "            sigma_minutes = val * 60\n",
    "        else:\n",
    "            sigma_minutes = val\n",
    "    return to_grid, date, sigma_minutes\n",
    "\n",
    "\n",
    "def prepare_sequences(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Sort by user & stime, build next fields and indices.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"stime\"] = pd.to_datetime(df[\"stime\"], errors=\"coerce\")\n",
    "    df[\"etime\"] = pd.to_datetime(df[\"etime\"], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"userID\", \"stime\", \"etime\", \"grid\"]).copy()\n",
    "    df[\"userID\"] = df[\"userID\"].astype(int)\n",
    "    df[\"grid\"] = df[\"grid\"].astype(int)\n",
    "\n",
    "    df = df.sort_values([\"userID\", \"stime\"]).reset_index(drop=True)\n",
    "    df[\"idx_in_user\"] = df.groupby(\"userID\").cumcount()\n",
    "\n",
    "    # next stay info\n",
    "    df[\"next_grid\"] = df.groupby(\"userID\")[\"grid\"].shift(-1)\n",
    "    df[\"next_stime\"] = df.groupby(\"userID\")[\"stime\"].shift(-1)\n",
    "    df[\"next_etime\"] = df.groupby(\"userID\")[\"etime\"].shift(-1)\n",
    "\n",
    "    # time deltas\n",
    "    df[\"stay_duration_min\"] = (df[\"etime\"] - df[\"stime\"]).dt.total_seconds() / 60.0\n",
    "    df[\"inter_stay_gap_min\"] = (df[\"next_stime\"] - df[\"etime\"]).dt.total_seconds() / 60.0\n",
    "    # gaps can be negative due to noise; clip for hist\n",
    "    df[\"inter_stay_gap_min_clip\"] = df[\"inter_stay_gap_min\"].clip(lower=0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) User activity & scale\n",
    "# -----------------------------\n",
    "def plot_user_activity(df: pd.DataFrame, outdir: str):\n",
    "    ensure_dir(outdir)\n",
    "    palette = plt.get_cmap(\"tab10\").colors\n",
    "\n",
    "    n_users = df[\"userID\"].nunique()\n",
    "    n_stays = len(df)\n",
    "    n_trans = df[\"next_grid\"].notna().sum()\n",
    "\n",
    "    stays_per_user = df.groupby(\"userID\").size().astype(int)\n",
    "    span_days = (df.groupby(\"userID\")[\"etime\"].max() - df.groupby(\"userID\")[\"stime\"].min()).dt.total_seconds() / (24*3600)\n",
    "\n",
    "    summary = {\n",
    "        \"n_users\": int(n_users),\n",
    "        \"n_stays\": int(n_stays),\n",
    "        \"n_transitions\": int(n_trans),\n",
    "        \"stays_per_user_mean\": float(stays_per_user.mean()),\n",
    "        \"stays_per_user_median\": float(stays_per_user.median()),\n",
    "        \"stays_per_user_std\": float(stays_per_user.std()),\n",
    "        \"stays_per_user_IQR\": float(stays_per_user.quantile(0.75) - stays_per_user.quantile(0.25)),\n",
    "        \"span_days_mean\": float(span_days.mean()),\n",
    "        \"span_days_median\": float(span_days.median()),\n",
    "    }\n",
    "    print(\"[User Activity Summary]\")\n",
    "    for k, v in summary.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4.5))\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    nice_hist(\n",
    "        ax1,\n",
    "        stays_per_user.values,\n",
    "        bins=50,\n",
    "        logx=True,\n",
    "        logy=True,\n",
    "        title=f\"Stays per user (log-log) | users={n_users}, stays={n_stays}\",\n",
    "        xlabel=\"#stays per user\",\n",
    "        ylabel=\"count of users\",\n",
    "        color=palette[0],\n",
    "    )\n",
    "\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    nice_hist(\n",
    "        ax2,\n",
    "        span_days.values,\n",
    "        bins=50,\n",
    "        logx=True,\n",
    "        logy=True,\n",
    "        title=\"Time span per user (log-log)\",\n",
    "        xlabel=\"span (days)\",\n",
    "        ylabel=\"count of users\",\n",
    "        color=palette[1],\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(outdir, \"01_user_activity_scale.pdf\"), dpi=220)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Transition entropy / uncertainty\n",
    "# -----------------------------\n",
    "def compute_user_visit_entropy(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"H_u over visited grids for each user.\"\"\"\n",
    "    ent = {}\n",
    "    for uid, g in df.groupby(\"userID\"):\n",
    "        counts = g[\"grid\"].value_counts().values\n",
    "        ent[uid] = entropy_from_counts(counts, base=2.0)\n",
    "    return pd.Series(ent, name=\"visit_entropy_bits\")\n",
    "\n",
    "\n",
    "def compute_user_conditional_transition_entropy(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    H_u(next|curr) = sum_{curr} p(curr) * H(next|curr).\n",
    "    \"\"\"\n",
    "    ent = {}\n",
    "    for uid, g in df.groupby(\"userID\"):\n",
    "        trans = g.dropna(subset=[\"next_grid\"])\n",
    "        if len(trans) == 0:\n",
    "            ent[uid] = 0.0\n",
    "            continue\n",
    "        # group by current grid\n",
    "        total = len(trans)\n",
    "        H = 0.0\n",
    "        for curr, gg in trans.groupby(\"grid\"):\n",
    "            w = len(gg) / total\n",
    "            counts = gg[\"next_grid\"].value_counts().values\n",
    "            H += w * entropy_from_counts(counts, base=2.0)\n",
    "        ent[uid] = float(H)\n",
    "    return pd.Series(ent, name=\"cond_entropy_bits\")\n",
    "\n",
    "\n",
    "def compute_global_cond_entropy_by_curr(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"For each current grid, compute H(next|curr) across all users.\"\"\"\n",
    "    trans = df.dropna(subset=[\"next_grid\"])\n",
    "    ent = {}\n",
    "    for curr, g in trans.groupby(\"grid\"):\n",
    "        counts = g[\"next_grid\"].value_counts().values\n",
    "        ent[curr] = entropy_from_counts(counts, base=2.0)\n",
    "    return pd.Series(ent, name=\"H_next_given_curr_bits\")\n",
    "\n",
    "\n",
    "def plot_entropy(df: pd.DataFrame, outdir: str):\n",
    "    ensure_dir(outdir)\n",
    "    palette = plt.get_cmap(\"tab10\").colors\n",
    "\n",
    "    visit_H = compute_user_visit_entropy(df)\n",
    "    cond_H = compute_user_conditional_transition_entropy(df)\n",
    "    curr_H = compute_global_cond_entropy_by_curr(df)\n",
    "\n",
    "    # Plot user-level entropies\n",
    "    fig = plt.figure(figsize=(12, 4.5))\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    nice_hist(\n",
    "        ax1, visit_H.values, bins=50, logx=False, logy=True,\n",
    "        title=\"User visit entropy H(grid | user)\",\n",
    "        xlabel=\"entropy (bits)\", ylabel=\"users\",\n",
    "        color=palette[2]\n",
    "    )\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    nice_hist(\n",
    "        ax2, cond_H.values, bins=50, logx=False, logy=True,\n",
    "        title=\"User conditional transition entropy H(next | curr, user)\",\n",
    "        xlabel=\"entropy (bits)\", ylabel=\"users\",\n",
    "        color=palette[3]\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(outdir, \"02_user_entropy.pdf\"), dpi=220)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Plot grid-level conditional entropy (global)\n",
    "    fig = plt.figure(figsize=(6.2, 4.5))\n",
    "    ax = plt.gca()\n",
    "    nice_hist(\n",
    "        ax, curr_H.values, bins=60, logx=False, logy=True,\n",
    "        title=\"Global H(next | current grid)\",\n",
    "        xlabel=\"entropy (bits)\", ylabel=\"grids\",\n",
    "        color=palette[4]\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(outdir, \"03_global_cond_entropy_by_grid.pdf\"), dpi=220)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return {\n",
    "        \"visit_entropy_bits\": visit_H,\n",
    "        \"cond_entropy_bits\": cond_H,\n",
    "        \"global_cond_entropy_by_grid_bits\": curr_H\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Routine vs Aperiodic\n",
    "# -----------------------------\n",
    "def compute_topk_visit_ratio(df: pd.DataFrame, ks=(1, 3, 5)) -> pd.DataFrame:\n",
    "    \"\"\"Per-user top-k visit ratio.\"\"\"\n",
    "    rows = []\n",
    "    for uid, g in df.groupby(\"userID\"):\n",
    "        vc = g[\"grid\"].value_counts()\n",
    "        total = vc.sum()\n",
    "        for k in ks:\n",
    "            topk = vc.iloc[:k].sum() if len(vc) >= 1 else 0\n",
    "            rows.append({\"userID\": uid, \"k\": k, \"topk_ratio\": float(topk / total) if total > 0 else 0.0})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def routine_stats(df: pd.DataFrame, topN: int = 5):\n",
    "    \"\"\"Compute routine set per user (Top-N grids) and routine fractions.\"\"\"\n",
    "    routine_frac_stay = {}\n",
    "    routine_frac_next = {}\n",
    "\n",
    "    for uid, g in df.groupby(\"userID\"):\n",
    "        vc = g[\"grid\"].value_counts()\n",
    "        routine = set(vc.index[:topN])\n",
    "\n",
    "        # stays in routine\n",
    "        routine_frac_stay[uid] = float((g[\"grid\"].isin(routine)).mean())\n",
    "\n",
    "        # next in routine (transitions)\n",
    "        trans = g.dropna(subset=[\"next_grid\"])\n",
    "        if len(trans) == 0:\n",
    "            routine_frac_next[uid] = 0.0\n",
    "        else:\n",
    "            routine_frac_next[uid] = float((trans[\"next_grid\"].astype(int).isin(routine)).mean())\n",
    "\n",
    "    return pd.Series(routine_frac_stay, name=\"routine_stay_frac\"), pd.Series(routine_frac_next, name=\"routine_next_frac\")\n",
    "\n",
    "\n",
    "def plot_routine_vs_aperiodic(df: pd.DataFrame, outdir: str):\n",
    "    ensure_dir(outdir)\n",
    "    palette = plt.get_cmap(\"tab10\").colors\n",
    "\n",
    "    # Top-k ratio boxplot\n",
    "    topk_df = compute_topk_visit_ratio(df, ks=(1, 3, 5))\n",
    "    data_list = [topk_df[topk_df[\"k\"] == k][\"topk_ratio\"].values for k in (1, 3, 5)]\n",
    "    fig = plt.figure(figsize=(7.5, 4.8))\n",
    "    ax = plt.gca()\n",
    "    nice_box(\n",
    "        ax, data_list, labels=[\"Top-1\", \"Top-3\", \"Top-5\"],\n",
    "        title=\"Distribution of Top-k visit ratio across users\",\n",
    "        ylabel=\"visit ratio\",\n",
    "        colors=[palette[0], palette[1], palette[2]]\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(outdir, \"04_topk_visit_ratio.pdf\"), dpi=220)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Routine vs tail fractions\n",
    "    routine_stay, routine_next = routine_stats(df, topN=5)\n",
    "    fig = plt.figure(figsize=(12, 4.5))\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    nice_hist(\n",
    "        ax1, routine_stay.values, bins=50, logx=False, logy=True,\n",
    "        title=\"Fraction of stays in routine (Top-5 locations)\",\n",
    "        xlabel=\"routine stay fraction\", ylabel=\"users\",\n",
    "        color=palette[5]\n",
    "    )\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    nice_hist(\n",
    "        ax2, routine_next.values, bins=50, logx=False, logy=True,\n",
    "        title=\"Fraction of next-stays in routine (Top-5 locations)\",\n",
    "        xlabel=\"routine next fraction\", ylabel=\"users\",\n",
    "        color=palette[6]\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(outdir, \"05_routine_vs_tail.pdf\"), dpi=220)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Global average (single bar summary)\n",
    "    global_stay = float(routine_stay.mean())\n",
    "    global_next = float(routine_next.mean())\n",
    "    fig = plt.figure(figsize=(5.8, 4.5))\n",
    "    ax = plt.gca()\n",
    "    ax.bar([\"stay in routine\", \"next in routine\"], [global_stay, global_next],\n",
    "           color=[palette[5], palette[6]], alpha=0.85, edgecolor=\"white\", linewidth=0.8)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.set_title(\"Global routine fractions (mean across users)\", pad=10)\n",
    "    ax.set_ylabel(\"fraction\")\n",
    "    ax.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.6, alpha=0.35)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(outdir, \"06_global_routine_fractions.pdf\"), dpi=220)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return {\"topk_df\": topk_df, \"routine_stay_frac\": routine_stay, \"routine_next_frac\": routine_next}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Time uncertainty distributions\n",
    "# -----------------------------\n",
    "def plot_time_uncertainty(df: pd.DataFrame, outdir: str):\n",
    "    ensure_dir(outdir)\n",
    "    palette = plt.get_cmap(\"tab10\").colors\n",
    "\n",
    "    dur = df[\"stay_duration_min\"].values\n",
    "    gap = df[\"inter_stay_gap_min_clip\"].dropna().values\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4.5))\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    nice_hist(\n",
    "        ax1, dur, bins=70, logx=True, logy=True,\n",
    "        title=\"Stay duration distribution (log-log)\",\n",
    "        xlabel=\"duration (minutes)\", ylabel=\"stays\",\n",
    "        color=palette[7]\n",
    "    )\n",
    "\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    nice_hist(\n",
    "        ax2, gap, bins=70, logx=True, logy=True,\n",
    "        title=\"Inter-stay gap distribution (log-log)\",\n",
    "        xlabel=\"gap (minutes)\", ylabel=\"transitions\",\n",
    "        color=palette[8]\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(outdir, \"07_time_uncertainty.pdf\"), dpi=220)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5-6) Context availability & alignment\n",
    "# -----------------------------\n",
    "def build_user_index(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Build per-user lookup:\n",
    "    - by exact stime: map Timestamp -> (idx_in_user, grid)\n",
    "    - also list of stimes for nearest match if needed\n",
    "    \"\"\"\n",
    "    user_maps = {}\n",
    "    for uid, g in df.groupby(\"userID\"):\n",
    "        g2 = g[[\"idx_in_user\", \"stime\", \"grid\"]].copy()\n",
    "        exact = {t: (int(i), int(gr)) for i, t, gr in zip(g2[\"idx_in_user\"], g2[\"stime\"], g2[\"grid\"])}\n",
    "        # for nearest matching\n",
    "        stimes = g2[\"stime\"].values\n",
    "        user_maps[uid] = {\"exact\": exact, \"g\": g2}\n",
    "    return user_maps\n",
    "\n",
    "\n",
    "def match_precise_alignment(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each row with context_precise, parse (to_grid, target_time),\n",
    "    then match to user's stay whose stime == target_time (exact).\n",
    "    Return per-context stats:\n",
    "      - matched (bool)\n",
    "      - step_distance (matched_idx - curr_idx)\n",
    "      - time_error_min (target_time - matched_stime)\n",
    "      - grid_match (bool)\n",
    "    \"\"\"\n",
    "    user_maps = build_user_index(df)\n",
    "    records = []\n",
    "    for r in df.itertuples(index=False):\n",
    "        uid = int(r.userID)\n",
    "        curr_idx = int(r.idx_in_user)\n",
    "        txt = getattr(r, \"context_precise\")\n",
    "        to_grid, t = parse_context_precise(txt)\n",
    "\n",
    "        if to_grid is None or t is None:\n",
    "            continue\n",
    "\n",
    "        exact = user_maps[uid][\"exact\"]\n",
    "        if t in exact:\n",
    "            matched_idx, matched_grid = exact[t]\n",
    "            records.append({\n",
    "                \"userID\": uid,\n",
    "                \"curr_idx\": curr_idx,\n",
    "                \"to_grid\": int(to_grid),\n",
    "                \"target_time\": t,\n",
    "                \"matched\": True,\n",
    "                \"matched_idx\": matched_idx,\n",
    "                \"matched_grid\": matched_grid,\n",
    "                \"step_distance\": int(matched_idx - curr_idx),\n",
    "                \"time_error_min\": 0.0,  # exact match\n",
    "                \"grid_match\": bool(int(matched_grid) == int(to_grid)),\n",
    "            })\n",
    "        else:\n",
    "            records.append({\n",
    "                \"userID\": uid,\n",
    "                \"curr_idx\": curr_idx,\n",
    "                \"to_grid\": int(to_grid),\n",
    "                \"target_time\": t,\n",
    "                \"matched\": False,\n",
    "                \"matched_idx\": np.nan,\n",
    "                \"matched_grid\": np.nan,\n",
    "                \"step_distance\": np.nan,\n",
    "                \"time_error_min\": np.nan,\n",
    "                \"grid_match\": False,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def match_fuzzy_alignment(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For fuzzy context: parse (to_grid, date, sigma_minutes).\n",
    "    We match by looking for user's stay with same grid on that date (any time),\n",
    "    picking the first occurrence on that date (by stime) to estimate alignment.\n",
    "    Returns:\n",
    "      - matched(bool)\n",
    "      - step_distance (matched_idx - curr_idx)\n",
    "      - day_error (matched_date - context_date, in days)\n",
    "      - sigma_minutes (from text if available)\n",
    "    \"\"\"\n",
    "    # precompute for each user: (date, grid) -> earliest idx/stime\n",
    "    index = {}\n",
    "    for uid, g in df.groupby(\"userID\"):\n",
    "        g2 = g[[\"idx_in_user\", \"stime\", \"grid\"]].copy()\n",
    "        g2[\"date\"] = g2[\"stime\"].dt.normalize()\n",
    "        # earliest occurrence\n",
    "        key_map = {}\n",
    "        for rr in g2.sort_values(\"stime\").itertuples(index=False):\n",
    "            key = (rr.date, int(rr.grid))\n",
    "            if key not in key_map:\n",
    "                key_map[key] = (int(rr.idx_in_user), rr.stime)\n",
    "        index[int(uid)] = key_map\n",
    "\n",
    "    records = []\n",
    "    for r in df.itertuples(index=False):\n",
    "        uid = int(r.userID)\n",
    "        curr_idx = int(r.idx_in_user)\n",
    "        txt = getattr(r, \"context_fuzzy\")\n",
    "        to_grid, d, sigma_min = parse_context_fuzzy(txt)\n",
    "        if to_grid is None or d is None:\n",
    "            continue\n",
    "        key = (d, int(to_grid))\n",
    "        key_map = index.get(uid, {})\n",
    "        if key in key_map:\n",
    "            matched_idx, matched_stime = key_map[key]\n",
    "            day_error = (matched_stime.normalize() - d).days\n",
    "            records.append({\n",
    "                \"userID\": uid,\n",
    "                \"curr_idx\": curr_idx,\n",
    "                \"to_grid\": int(to_grid),\n",
    "                \"context_date\": d,\n",
    "                \"matched\": True,\n",
    "                \"matched_idx\": matched_idx,\n",
    "                \"matched_stime\": matched_stime,\n",
    "                \"step_distance\": int(matched_idx - curr_idx),\n",
    "                \"day_error\": float(day_error),\n",
    "                \"sigma_minutes\": float(sigma_min) if sigma_min is not None else np.nan,\n",
    "            })\n",
    "        else:\n",
    "            records.append({\n",
    "                \"userID\": uid,\n",
    "                \"curr_idx\": curr_idx,\n",
    "                \"to_grid\": int(to_grid),\n",
    "                \"context_date\": d,\n",
    "                \"matched\": False,\n",
    "                \"matched_idx\": np.nan,\n",
    "                \"matched_stime\": pd.NaT,\n",
    "                \"step_distance\": np.nan,\n",
    "                \"day_error\": np.nan,\n",
    "                \"sigma_minutes\": float(sigma_min) if sigma_min is not None else np.nan,\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def plot_context_stats(df: pd.DataFrame, outdir: str):\n",
    "    ensure_dir(outdir)\n",
    "    palette = plt.get_cmap(\"tab10\").colors\n",
    "\n",
    "    # Availability\n",
    "    has_fuzzy = df[\"context_fuzzy\"].notna().mean()\n",
    "    has_precise = df[\"context_precise\"].notna().mean()\n",
    "    both = (df[\"context_fuzzy\"].notna() & df[\"context_precise\"].notna()).mean()\n",
    "\n",
    "    fig = plt.figure(figsize=(6.2, 4.5))\n",
    "    ax = plt.gca()\n",
    "    ax.bar([\"fuzzy\", \"precise\", \"both\"], [has_fuzzy, has_precise, both],\n",
    "           color=[palette[0], palette[1], palette[2]],\n",
    "           alpha=0.85, edgecolor=\"white\", linewidth=0.8)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.set_title(\"Context availability ratio\", pad=10)\n",
    "    ax.set_ylabel(\"ratio\")\n",
    "    ax.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.6, alpha=0.35)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(outdir, \"08_context_availability.pdf\"), dpi=220)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Precise alignment\n",
    "    precise_df = match_precise_alignment(df)\n",
    "    if len(precise_df) > 0:\n",
    "        match_rate = precise_df[\"matched\"].mean()\n",
    "        grid_match_rate = (precise_df[\"matched\"] & precise_df[\"grid_match\"]).mean()\n",
    "\n",
    "        # step distance distribution (matched only)\n",
    "        sd = precise_df.loc[precise_df[\"matched\"], \"step_distance\"].values\n",
    "        sd = sd[np.isfinite(sd) & (sd >= 1)]  # future steps\n",
    "        fig = plt.figure(figsize=(12, 4.5))\n",
    "        ax1 = plt.subplot(1, 2, 1)\n",
    "        nice_hist(\n",
    "            ax1, sd, bins=60, logx=False, logy=True,\n",
    "            title=f\"Precise context step distance (matched)\\nmatch={match_rate:.3f}, grid_match={grid_match_rate:.3f}\",\n",
    "            xlabel=\"matched_idx - curr_idx (steps)\", ylabel=\"contexts\",\n",
    "            color=palette[3]\n",
    "        )\n",
    "\n",
    "        # grid match (bar)\n",
    "        ax2 = plt.subplot(1, 2, 2)\n",
    "        ax2.bar([\"matched\", \"grid matched\"], [match_rate, grid_match_rate],\n",
    "                color=[palette[4], palette[5]], alpha=0.85, edgecolor=\"white\", linewidth=0.8)\n",
    "        ax2.set_ylim(0, 1.0)\n",
    "        ax2.set_title(\"Precise context matching rates\", pad=10)\n",
    "        ax2.set_ylabel(\"ratio\")\n",
    "        ax2.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.6, alpha=0.35)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(os.path.join(outdir, \"09_precise_alignment.pdf\"), dpi=220)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Fuzzy alignment\n",
    "    fuzzy_df = match_fuzzy_alignment(df)\n",
    "    if len(fuzzy_df) > 0:\n",
    "        match_rate = fuzzy_df[\"matched\"].mean()\n",
    "\n",
    "        sd = fuzzy_df.loc[fuzzy_df[\"matched\"], \"step_distance\"].values\n",
    "        sd = sd[np.isfinite(sd) & (sd >= 1)]\n",
    "        sigma = fuzzy_df[\"sigma_minutes\"].values\n",
    "        sigma = sigma[np.isfinite(sigma) & (sigma > 0)]\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 4.5))\n",
    "        ax1 = plt.subplot(1, 2, 1)\n",
    "        nice_hist(\n",
    "            ax1, sd, bins=60, logx=False, logy=True,\n",
    "            title=f\"Fuzzy context step distance (matched)\\nmatch={match_rate:.3f}\",\n",
    "            xlabel=\"matched_idx - curr_idx (steps)\", ylabel=\"contexts\",\n",
    "            color=palette[6]\n",
    "        )\n",
    "        ax2 = plt.subplot(1, 2, 2)\n",
    "        if len(sigma) > 0:\n",
    "            nice_hist(\n",
    "                ax2, sigma, bins=60, logx=True, logy=True,\n",
    "                title=\"Fuzzy context uncertainty proxy (sigma minutes)\",\n",
    "                xlabel=\"sigma (minutes, log)\", ylabel=\"contexts\",\n",
    "                color=palette[7]\n",
    "            )\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, \"No parsable sigma in fuzzy texts\", ha=\"center\", va=\"center\")\n",
    "            ax2.set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(os.path.join(outdir, \"10_fuzzy_alignment.pdf\"), dpi=220)\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(\"[Context Availability]\")\n",
    "    print(f\"  fuzzy:   {has_fuzzy:.4f}\")\n",
    "    print(f\"  precise: {has_precise:.4f}\")\n",
    "    print(f\"  both:    {both:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"availability\": {\"fuzzy\": has_fuzzy, \"precise\": has_precise, \"both\": both},\n",
    "        \"precise_alignment_df\": precise_df,\n",
    "        \"fuzzy_alignment_df\": fuzzy_df,\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "def main(csv_path: str, outdir: str = \"figures\"):\n",
    "    ensure_dir(outdir)\n",
    "\n",
    "    df_raw = pd.read_csv(csv_path)\n",
    "    df = prepare_sequences(df_raw)\n",
    "\n",
    "    # 1) user activity\n",
    "    plot_user_activity(df, outdir)\n",
    "\n",
    "    # 2) entropies\n",
    "    plot_entropy(df, outdir)\n",
    "\n",
    "    # 3) routine vs aperiodic\n",
    "    plot_routine_vs_aperiodic(df, outdir)\n",
    "\n",
    "    # 4) time uncertainty distributions\n",
    "    plot_time_uncertainty(df, outdir)\n",
    "\n",
    "    # 5-6) context availability & alignment\n",
    "    plot_context_stats(df, outdir)\n",
    "\n",
    "    print(f\"\\nAll figures saved to: {os.path.abspath(outdir)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Change to your actual path if needed:\n",
    "    CSV_PATH = \"./Data/Output/all_users_context_combined.csv\"\n",
    "    main(CSV_PATH, outdir=\"./Pictures/GeoLife/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157c6638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[User Activity Summary]\n",
      "  n_users: 9907\n",
      "  n_stays: 6818428\n",
      "  n_transitions: 6808521\n",
      "  stays_per_user_mean: 688.2434642172201\n",
      "  stays_per_user_median: 654.0\n",
      "  stays_per_user_std: 398.82448697097675\n",
      "  stays_per_user_IQR: 592.0\n",
      "  span_days_mean: 168.68627095179616\n",
      "  span_days_median: 170.24101851851853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_12932\\2149088866.py:59: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  bp = ax.boxplot(data_list, labels=labels, patch_artist=True, showfliers=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Context Availability]\n",
      "  fuzzy:   0.2616\n",
      "  precise: 0.2616\n",
      "  both:    0.2616\n",
      "\n",
      "All figures saved to: d:\\codeSpace\\TrajectoryFeatureGeneration\\Pictures\\MoreUser\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"./Data/MoreUser/all.csv\"\n",
    "main(CSV_PATH, outdir=\"./Pictures/MoreUser/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
