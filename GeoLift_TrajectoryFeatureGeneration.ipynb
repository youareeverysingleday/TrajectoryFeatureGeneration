{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72680939",
   "metadata": {},
   "source": [
    "# 生成轨迹特征\n",
    "\n",
    "1. 将每个用户的所有plt文件都合并为1个csv文件。\n",
    "2. 生成停留点和移动点。\n",
    "3. 删除异常值。\n",
    "   1. 删除超过设定城市区域范围之外的轨迹。\n",
    "   2. 停留时间超过一周的停留点。因为数据是都按天提供的。\n",
    "4. 生成指定数据格式的轨迹数据。\n",
    "   1. 生成时序数据。\n",
    "   2. 矩阵数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b9a3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import transbigdata as tbd\n",
    "from typing import Tuple, List\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from Utils import CalcGrid, OperJson\n",
    "\n",
    "gParameters = OperJson.JSONConfig('./Parameters.json')\n",
    "# print(gParameters.get('gPreprocessDataSavePath'))\n",
    "# lon1, lat1, lon2, lat2\n",
    "gGeoParameters = tbd.area_to_params(location = gParameters.get('gBoundsBeijing'), \n",
    "                                    accuracy = gParameters.get('gAccuracy'), \n",
    "                                    method = gParameters.get('gMethod'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e6db84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34203"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CG_Ellipsoid = CalcGrid.GridMapperEllipsoid(gParameters.get('gBoundsBeijing')[0], \n",
    "                         gParameters.get('gBoundsBeijing')[1], \n",
    "                         gParameters.get('gBoundsBeijing')[2],\n",
    "                         gParameters.get('gBoundsBeijing')[3],\n",
    "                         cell_size_m=1000)\n",
    "\n",
    "testgrid = CG_Ellipsoid.lonlat_to_grid(117.52, 41.05)\n",
    "testgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b235cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "049 generate null stay, dataframe is null.\n",
      "118 after clean out of bounds, dataframe is null.\n",
      "120 generate null stay, dataframe is null.\n",
      "123 generate null stay, dataframe is null.\n",
      "132 after clean out of bounds, dataframe is null.\n",
      "137 generate null stay, dataframe is null.\n",
      "160 after clean out of bounds, dataframe is null.\n",
      "178 generate null stay, dataframe is null.\n",
      "180 Duration is less than the threshold, dataframe is null.\n"
     ]
    }
   ],
   "source": [
    "gUsersList = next(os.walk(gParameters.get('gTrajectoryFolderPath')))[1]\n",
    "# gUsersList\n",
    "\n",
    "\n",
    "def GenerateStayMove(userID:str) -> bool:\n",
    "    \"\"\"_summary_\n",
    "    对一个用户生成停留点和移动特征。\n",
    "    Args:\n",
    "        userID (str): 用户的ID。\n",
    "\n",
    "    Returns:\n",
    "        bool: 是否报错，用于在上级循环中退出。\n",
    "    \"\"\"\n",
    "    \n",
    "    ErrorFlag = False\n",
    "    gTrajectoryFolderPath = gParameters.get('gTrajectoryFolderPath')\n",
    "    userdata = gTrajectoryFolderPath + '/{}/Trajectory/'.format(userID)\n",
    "\n",
    "    # 返回指定路径下所有文件和文件夹的名字，并存放于一个列表中\n",
    "    filelist = os.listdir(userdata)\n",
    "    # plt文件中的字段名称。\n",
    "    names = ['lat','lng','zero','alt','days','date','time']\n",
    "    # 读取一个用户目录下的所有轨迹文件。\n",
    "    df_list = [pd.read_csv(userdata + f, header=6, names=names, index_col=False) for f in filelist]\n",
    "    # 将轨迹文件合并。\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    # 规范时间格式。\n",
    "    df['entireTime'] = pd.to_datetime((df['date'] + ' ' + df['time']), format='%Y-%m-%d %H:%M:%S')\n",
    "    # 修改列名。\n",
    "    df.rename(columns={'lat': 'latitude', 'lng': 'longitude'}, inplace=True)\n",
    "    # 删除不需要使用的列。\n",
    "    df.drop(['zero', 'days', 'date', 'time', 'alt'], axis=1, inplace=True)\n",
    "\n",
    "    # print(df.shape)\n",
    "    # 删除超过定义范围之外的点。\n",
    "    df = tbd.clean_outofbounds(df, bounds = gParameters.get('gBoundsBeijing'), \n",
    "                            col = ['longitude', 'latitude'])\n",
    "    # print(df.shape)\n",
    "    if df.shape[0] == 0:\n",
    "        print(f'{userID} after clean out of bounds, dataframe is null.')\n",
    "        ErrorFlag = True\n",
    "        return ErrorFlag\n",
    "    # 添加userID列。\n",
    "    df['userID'] = userID\n",
    "    # df.head(3)\n",
    "\n",
    "    # 生成停留点。\n",
    "    stay, move = tbd.traj_stay_move(df, gGeoParameters,\n",
    "                                        col=['userID', 'entireTime', 'longitude', 'latitude'], \n",
    "                                        activitytime=gParameters.get('gActivityTime'))\n",
    "    if stay.shape[0] == 0:\n",
    "        print(f'{userID} generate null stay, dataframe is null.')\n",
    "        ErrorFlag = True\n",
    "        return ErrorFlag\n",
    "    \n",
    "    # 删除停留点时间超过一周的停留点。\n",
    "    # 因为geolife 中都是按天提供轨迹数据的。其中有部分数据的时间间隔是间断（超过一天）的。所以需要删除异常值。\n",
    "    # print(stay)\n",
    "    stay = stay[stay['duration'] <= gParameters.get('gStayDurationthreshold')]\n",
    "    if stay.shape[0] == 0:\n",
    "        print(f'{userID} Duration is less than the threshold, dataframe is null.')\n",
    "        ErrorFlag = True\n",
    "        return ErrorFlag\n",
    "\n",
    "    # print(stay.columns)\n",
    "    # 生成自定义的grid。\n",
    "    def GenerateStayGrid(df):\n",
    "        df['grid'] = CG_Ellipsoid.lonlat_to_grid(df['lon'], df['lat'])\n",
    "        return df\n",
    "    stay = stay.apply(GenerateStayGrid, axis=1)\n",
    "\n",
    "    # 删除没有使用的列名。\n",
    "    stay = stay[['userID', 'stime', 'etime', 'lon', 'lat', 'duration', 'grid']]\n",
    "    stay.to_csv(gParameters.get('gSingleUserStaySavePath').format(userID))\n",
    "\n",
    "    def GenerateMoveGrid(df):\n",
    "        df['sgrid'] = CG_Ellipsoid.lonlat_to_grid(df['slon'], df['slat'])\n",
    "        df['egrid'] = CG_Ellipsoid.lonlat_to_grid(df['elon'], df['elat'])\n",
    "        return df\n",
    "    move = move.apply(GenerateMoveGrid, axis=1)\n",
    "    move = move[['userID', 'stime', 'slon', 'slat', 'sgrid', 'etime', 'elon', 'elat', 'egrid', 'duration']]\n",
    "    # move\n",
    "    move.to_csv(gParameters.get('gSingleUserMoveSavePath').format(userID))\n",
    "    # print(f'{userID} has generated stay and move.')\n",
    "    return ErrorFlag\n",
    "\n",
    "\n",
    "# GenerateStayMove('049')\n",
    "\n",
    "for userID in gUsersList:\n",
    "    if GenerateStayMove(userID=userID):\n",
    "        # raise ValueError(f\"{userID} report ERROR.\")\n",
    "        continue\n",
    "\n",
    "# consume 1m 38.4s ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47594cfa",
   "metadata": {},
   "source": [
    "generate record:\n",
    "\n",
    "- 049 generate null stay, dataframe is null.\n",
    "- 118 after clean out of bounds, dataframe is null.\n",
    "- 120 generate null stay, dataframe is null.\n",
    "- 123 generate null stay, dataframe is null.\n",
    "- 132 after clean out of bounds, dataframe is null.\n",
    "- 137 generate null stay, dataframe is null.\n",
    "- 160 after clean out of bounds, dataframe is null.\n",
    "- 178 generate null stay, dataframe is null.\n",
    "- 180 Duration is less than the threshold, dataframe is null."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa88e064",
   "metadata": {},
   "source": [
    "# 将每个人的轨迹都合并为一个CSV文件用于模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807d0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27919, 7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取该路径下的所有文件。\n",
    "filelist = os.listdir(\"./Data/Output/Stays/\")\n",
    "# 读取所有的CSV，并且存入链表。\n",
    "df_list = [pd.read_csv(\"./Data/Output/Stays/\" + f, index_col=0, dtype={'userID': object}) for f in filelist]\n",
    "# 合并。\n",
    "AllStays = pd.concat(df_list, ignore_index=True)\n",
    "# 显示形状。\n",
    "AllStays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f36c8413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>stime</th>\n",
       "      <th>etime</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>duration</th>\n",
       "      <th>grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 03:01:40</td>\n",
       "      <td>2008-10-23 04:08:07</td>\n",
       "      <td>116.301309</td>\n",
       "      <td>39.984345</td>\n",
       "      <td>3987.0</td>\n",
       "      <td>14428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 04:30:57</td>\n",
       "      <td>2008-10-23 09:44:15</td>\n",
       "      <td>116.322261</td>\n",
       "      <td>39.998151</td>\n",
       "      <td>18798.0</td>\n",
       "      <td>14808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 09:44:15</td>\n",
       "      <td>2008-10-23 10:14:21</td>\n",
       "      <td>116.321396</td>\n",
       "      <td>40.007122</td>\n",
       "      <td>1806.0</td>\n",
       "      <td>14809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID                stime                etime         lon        lat  \\\n",
       "0       0  2008-10-23 03:01:40  2008-10-23 04:08:07  116.301309  39.984345   \n",
       "1       0  2008-10-23 04:30:57  2008-10-23 09:44:15  116.322261  39.998151   \n",
       "2       0  2008-10-23 09:44:15  2008-10-23 10:14:21  116.321396  40.007122   \n",
       "\n",
       "   duration   grid  \n",
       "0    3987.0  14428  \n",
       "1   18798.0  14808  \n",
       "2    1806.0  14809  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllStays.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81a9448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存。\n",
    "AllStays.to_csv('./Data/Output/AllUserTimeSeries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b3c2b",
   "metadata": {},
   "source": [
    "# 生成交互矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04a0c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractionMatrix = pd.pivot_table(AllStays[['userID', 'grid', 'duration']], index='userID',columns='grid', values='duration', aggfunc='count')\n",
    "InteractionMatrix.fillna(0, inplace=True)\n",
    "InteractionMatrix.to_csv('./Data/Output/InteractionMatrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42758af9",
   "metadata": {},
   "source": [
    "# 生成类似自然语言的Grid矩阵\n",
    "\n",
    "1. 按8：2的比例分了训练集和测试集。\n",
    "2. 可调参的矩阵第二个维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ade304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 12, 16] [0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "def list_split(input_list:List, ratio:float, shuffle=False)->Tuple[List, List]:\n",
    "    \"\"\"_summary_\n",
    "    数据集拆分: 将列表full_list按比例ratio（随机）划分为2个子列表sublist_1与sublist_2\n",
    "    Args:\n",
    "        input_list (List): 数据列表\n",
    "        ratio (float): 划分比例。\n",
    "        shuffle (bool, optional): 是否打乱. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List, List]: 返回划分好的两个链表。\n",
    "    \"\"\"\n",
    "    full_list = input_list\n",
    "    n_total = len(full_list)\n",
    "    offset = int(n_total * ratio)\n",
    "    if n_total == 0 or offset < 1:\n",
    "        return [], full_list\n",
    "    if shuffle:\n",
    "        # 打乱。\n",
    "        random.shuffle(full_list)\n",
    "    # 截取之后排序。\n",
    "    sublist_1 = sorted(full_list[:offset])\n",
    "    sublist_2 = sorted(full_list[offset:])\n",
    "    return sublist_1, sublist_2\n",
    " \n",
    "# 测试。\n",
    "data = list(range(20))\n",
    "sub_data1, sub_data2 = list_split(data, ratio=0.2, shuffle=True)\n",
    "print(sub_data1, sub_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe8797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 18\n"
     ]
    }
   ],
   "source": [
    "# 生成训练集和测试集。\n",
    "filelist = os.listdir(\"./Data/Output/Stays/\")\n",
    "trainUsers, testUsers = list_split(filelist, ratio=0.9, shuffle=True)\n",
    "print(len(trainUsers), len(testUsers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FormatTrajData(UserFileName:List) -> Tuple[pd.DataFrame, List]:\n",
    "    \"\"\"_summary_\n",
    "    将数据转化为类似于自然语言的矩阵形式。\n",
    "    Args:\n",
    "        UserFileName (List): 所有用户的csv文件名的list列表。\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, List]: 返回将所有用户合并之后的数据集， 有些用户的停留点数量小于需要转换为矩阵的第二个维度，所以直接丢弃了，丢弃的记录下来的列表。\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    delete_list = []\n",
    "    for f in UserFileName:\n",
    "        df = pd.read_csv(\"./Data/Output/Stays/\" + f, index_col=0, dtype={'userID': object}) \n",
    "        if df.shape[0] < gParameters.get('gMatrixSecondDimension'):\n",
    "            delete_list.append(f)\n",
    "            continue\n",
    "        # print(df.shape)\n",
    "        if df.shape[0] % gParameters.get('gMatrixSecondDimension') != 0:\n",
    "            # print(math.floor(df.shape[0]/gParameters.get('gMatrixSecondDimension')) * gParameters.get('gMatrixSecondDimension'))\n",
    "            temp = df.iloc[:math.floor(df.shape[0]/gParameters.get('gMatrixSecondDimension')) * gParameters.get('gMatrixSecondDimension'), :]\n",
    "            # print(temp.shape)\n",
    "            df_list.append(temp)\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    return df, delete_list\n",
    "\n",
    "\n",
    "trainData, trainDelUsers = FormatTrajData(trainUsers)\n",
    "testData, testDelUsers = FormatTrajData(testUsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split_twodimension(sequence, windows_length=100, step_length=1):\n",
    "    \"\"\"_summary_\n",
    "    将一个二维矩阵通过滑动窗口划分为样本和标签。\n",
    "    标签取样本之后的第一个值。\n",
    "    这个序列是按行进行的时间序列。\n",
    "    Args:\n",
    "        sequence (numpy.array): 三维矩阵，类似于文本的形状。\n",
    "        windows_length (int, optional): 滑动窗口的长度. Defaults to 100.\n",
    "        step_length (int, optional): 移动滑动窗口的步长. Defaults to 1.\n",
    "    Returns:\n",
    "        np.array(x) (numpy.array): 二维数组，样本。\n",
    "        np.array(y) (numpy.array): 二维数组，标签。\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(math.ceil(len(sequence)/step_length)):\n",
    "        labelIndex = step_length * i + windows_length\n",
    "        if labelIndex > len(sequence) - 1:\n",
    "            break\n",
    "        # sequence[i:labelIndex, :], sequence[labelIndex, :]\n",
    "        seq_x, seq_y = sequence[step_length*i:labelIndex, :], sequence[labelIndex, :]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a0ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2005, 10) (494, 10)\n",
      "(2004, 10) (2004, 10)\n"
     ]
    }
   ],
   "source": [
    "trainNp = trainData['grid'].values.reshape(-1, gParameters.get('gMatrixSecondDimension')) \n",
    "testNp = testData['grid'].values.reshape(-1, gParameters.get('gMatrixSecondDimension'))\n",
    "print(trainNp.shape, testNp.shape)\n",
    "\n",
    "trainSrc = trainNp[:-1, :]\n",
    "trainTgt = trainNp[1:, :]\n",
    "\n",
    "testSrc = testNp[:-1, :]\n",
    "testTgt = testNp[1:, :]\n",
    "\n",
    "print(trainSrc.shape, trainTgt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb23537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./Data/Output/StayTrainMatrix_{}.csv'.format(gParameters.get('gMatrixSecondDimension')), \n",
    "           trainNp, delimiter=',', fmt='%d')\n",
    "np.savetxt('./Data/Output/StayTestMatrix_{}.csv'.format(gParameters.get('gMatrixSecondDimension')), \n",
    "           testNp, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab369e",
   "metadata": {},
   "source": [
    "# 生成提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857db8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
