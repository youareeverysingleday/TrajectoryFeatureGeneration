{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037f0b31",
   "metadata": {},
   "source": [
    "# 对数据进行抽样\n",
    "\n",
    "1. 固定总样本数（Total stays 固定）\n",
    "   - 改变 users 数 U\n",
    "     - U In {500, 1k, 2k, 4k, 8k, 9.9k}\n",
    "     - N_total in {0.5M, 1M, 2M}, choose 1M.\n",
    "     - 每个用户至少有 (64 + 1) 个 stay，否则无法构造样本.\n",
    "   - 每用户长度 L 自动变化（L ≈ Total/U）\n",
    "   - 结论含义：用户多样性 vs 每用户密度 的 trade-off。\n",
    "   - We study the effect of user diversity under a fixed training budget. We fix the total number of stay tokens to N_total and vary the number of users U ∈ {0.5k, 1k, 2k, 4k, 8k, 10k}. For each U, we randomly sample users with at least 65 stays and subsample their trajectories to match N_total while preserving temporal order.\n",
    "2. 固定每用户长度（Per-user stays 固定）\n",
    "   - 改变 users 数 U。\n",
    "     - U in {500, 1k, 2k, 4k, 8k, 9.9k}\n",
    "   - 轨迹长度确定为500.\n",
    "   - 总样本数随之变化\n",
    "   - 结论含义：用户多样性 + 总样本量 的纯增益（更接近你当前观察）。不会出现“某些用户贡献 10 倍样本”的情况，因为它排除了 per-user sample imbalance。\n",
    "3. 固定 users 数（User count 固定）\n",
    "   - 用户数量规定为2000 。\n",
    "   - 改每用户长度 L。\n",
    "     - L in {100, 200, 500, 800, 1000}\n",
    "   - 观察是否存在“长度阈值”（比如超过某个长度模型突然变强）\n",
    "   - 结论含义：模型是否依赖长程结构（你论文“轨迹像语言”的论证点）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b036c4a",
   "metadata": {},
   "source": [
    "细节：\n",
    "1. 抽样采用random span sampling 方式的原因：\n",
    "   1. 如果使用整块的抽样容易学到位置偏置（position bias）。\n",
    "   2. 随机 span 训练迫使模型理解「这一整段缺失，我该如何从上下文中恢复？」"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac41e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a65e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 0) 列名自动识别（兼容 GeoLife 常见处理格式）\n",
    "# -----------------------------\n",
    "def _infer_columns(df: pd.DataFrame,\n",
    "                   user_col: str | None,\n",
    "                   time_col: str | None):\n",
    "    if user_col is None:\n",
    "        for c in [\"user_id\", \"userID\", \"uid\", \"UserId\", \"user\"]:\n",
    "            if c in df.columns:\n",
    "                user_col = c\n",
    "                break\n",
    "    if time_col is None:\n",
    "        for c in [\"timestamp\", \"time\", \"datetime\", \"stime\", \"t\"]:\n",
    "            if c in df.columns:\n",
    "                time_col = c\n",
    "                break\n",
    "\n",
    "    if user_col is None or time_col is None:\n",
    "        raise ValueError(\n",
    "            f\"无法自动识别 user/time 列。请显式传入 user_col/time_col。\\n\"\n",
    "            f\"当前列名：{list(df.columns)}\"\n",
    "        )\n",
    "    return user_col, time_col\n",
    "\n",
    "\n",
    "def _ensure_sorted(df: pd.DataFrame, user_col: str, time_col: str) -> pd.DataFrame:\n",
    "    # 保证每个用户内部时序正确（不打乱）\n",
    "    return df.sort_values([user_col, time_col]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def _random_contiguous_slice(idx: np.ndarray, length: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    给定某个用户的行索引 idx（已按时间排序），随机取一个连续片段，长度为 length。\n",
    "    如果刚好相等就全取。\n",
    "    \"\"\"\n",
    "    n = len(idx)\n",
    "    if n < length:\n",
    "        raise ValueError(\"User length not enough for slicing.\")\n",
    "    if n == length:\n",
    "        return idx\n",
    "    start = rng.integers(0, n - length + 1)\n",
    "    return idx[start:start + length]\n",
    "\n",
    "\n",
    "def _sample_users_with_min_stays(counts: pd.Series,\n",
    "                                 U: int,\n",
    "                                 min_stays: int,\n",
    "                                 rng: np.random.Generator) -> np.ndarray:\n",
    "    eligible = counts[counts >= min_stays].index.to_numpy()\n",
    "    if len(eligible) < U:\n",
    "        raise ValueError(f\"满足 min_stays={min_stays} 的用户只有 {len(eligible)} 个，不足 U={U}\")\n",
    "    return rng.choice(eligible, size=U, replace=False)\n",
    "\n",
    "\n",
    "def _save_df(df: pd.DataFrame, save_dir: str, filename: str):\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    path = Path(save_dir) / filename\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"[Saved] {path}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 固定总样本数（Total stays 固定）\n",
    "#    - 固定 N_total=1,000,000\n",
    "#    - 改变 U\n",
    "#    - 每个用户至少 65 stays\n",
    "#    - 每用户长度自动变化，且总 token 精确匹配 N_total\n",
    "# -----------------------------\n",
    "def sample_fixed_total_stays(\n",
    "    csv_path: str,\n",
    "    U: int,\n",
    "    N_total: int = 1_000_000,\n",
    "    min_stays: int = 65,\n",
    "    user_col: str | None = None,\n",
    "    time_col: str | None = None,\n",
    "    random_state: int = 42,\n",
    "    slice_mode: str = \"random_contiguous\",  # \"random_contiguous\" or \"prefix\"\n",
    "    save_dir: str = \"./samples\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each U:\n",
    "      - sample U users (each >= max(min_stays, required_length))\n",
    "      - allocate per-user length so that sum == N_total\n",
    "      - slice each user trajectory while preserving order\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    user_col, time_col = _infer_columns(df, user_col, time_col)\n",
    "    df = _ensure_sorted(df, user_col, time_col)\n",
    "\n",
    "    counts = df.groupby(user_col).size()\n",
    "\n",
    "    # 每用户长度分配：尽量平均，总和精确为 N_total\n",
    "    base = N_total // U\n",
    "    rem = N_total - base * U  # 0..U-1\n",
    "    lengths = np.full(U, base, dtype=int)\n",
    "    if rem > 0:\n",
    "        lengths[:rem] += 1\n",
    "\n",
    "    # 由于要能截取 length，每个用户至少要有 max(min_stays, base或base+1)\n",
    "    per_user_min_needed = max(min_stays, base + (1 if rem > 0 else 0))\n",
    "\n",
    "    sampled_users = _sample_users_with_min_stays(counts, U, per_user_min_needed, rng)\n",
    "\n",
    "    # 为了让 lengths 不与 user 顺序耦合：打乱 lengths 分配给 sampled_users（仍不影响用户内部时序）\n",
    "    rng.shuffle(lengths)\n",
    "\n",
    "    # 取索引并截取\n",
    "    pieces = []\n",
    "    for uid, L in zip(sampled_users, lengths):\n",
    "        idx = df.index[df[user_col] == uid].to_numpy()\n",
    "        if slice_mode == \"prefix\":\n",
    "            take_idx = idx[:L]\n",
    "        elif slice_mode == \"random_contiguous\":\n",
    "            take_idx = _random_contiguous_slice(idx, L, rng)\n",
    "        else:\n",
    "            raise ValueError(\"slice_mode must be 'random_contiguous' or 'prefix'\")\n",
    "        pieces.append(df.loc[take_idx])\n",
    "\n",
    "    out = pd.concat(pieces, axis=0)\n",
    "    out = _ensure_sorted(out, user_col, time_col)  # 每用户内部顺序保证；用户间也按时间+user排一下便于检查\n",
    "\n",
    "    # 断言总 token 数\n",
    "    if len(out) != N_total:\n",
    "        # 理论上不会发生；防御性检查\n",
    "        out = out.iloc[:N_total].copy()\n",
    "        out = _ensure_sorted(out, user_col, time_col)\n",
    "\n",
    "    # 保存：清晰区分策略 + 关键参数\n",
    "    filename = f\"geolife_S1_fixedTotal_N{N_total}_U{U}_min{min_stays}_seed{random_state}_{slice_mode}.csv\"\n",
    "    _save_df(out, save_dir, filename)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 固定每用户长度（Per-user stays 固定）\n",
    "#    - 改变 U\n",
    "#    - 每用户长度 L=500\n",
    "#    - 总 token 随 U 变化\n",
    "# -----------------------------\n",
    "def sample_fixed_per_user_stays(\n",
    "    csv_path: str,\n",
    "    U: int,\n",
    "    L: int = 500,\n",
    "    user_col: str | None = None,\n",
    "    time_col: str | None = None,\n",
    "    random_state: int = 42,\n",
    "    slice_mode: str = \"random_contiguous\",  # \"random_contiguous\" or \"prefix\"\n",
    "    save_dir: str = \"./samples\"\n",
    ") -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    user_col, time_col = _infer_columns(df, user_col, time_col)\n",
    "    df = _ensure_sorted(df, user_col, time_col)\n",
    "\n",
    "    counts = df.groupby(user_col).size()\n",
    "    sampled_users = _sample_users_with_min_stays(counts, U, L, rng)\n",
    "\n",
    "    pieces = []\n",
    "    for uid in sampled_users:\n",
    "        idx = df.index[df[user_col] == uid].to_numpy()\n",
    "        if slice_mode == \"prefix\":\n",
    "            take_idx = idx[:L]\n",
    "        elif slice_mode == \"random_contiguous\":\n",
    "            take_idx = _random_contiguous_slice(idx, L, rng)\n",
    "        else:\n",
    "            raise ValueError(\"slice_mode must be 'random_contiguous' or 'prefix'\")\n",
    "        pieces.append(df.loc[take_idx])\n",
    "\n",
    "    out = pd.concat(pieces, axis=0)\n",
    "    out = _ensure_sorted(out, user_col, time_col)\n",
    "\n",
    "    filename = f\"geolife_S2_fixedPerUser_U{U}_L{L}_seed{random_state}_{slice_mode}.csv\"\n",
    "    _save_df(out, save_dir, filename)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 固定 users 数（User count 固定）\n",
    "#    - 固定 U=2000\n",
    "#    - 改每用户长度 L in {100,200,500,800,1000}\n",
    "# -----------------------------\n",
    "def sample_fixed_user_count(\n",
    "    csv_path: str,\n",
    "    U: int = 2000,\n",
    "    L: int = 500,\n",
    "    min_stays: int | None = None,  # 可选：比如你想强制 >=65，则设为65；默认就是 L\n",
    "    user_col: str | None = None,\n",
    "    time_col: str | None = None,\n",
    "    random_state: int = 42,\n",
    "    slice_mode: str = \"random_contiguous\",  # \"random_contiguous\" or \"prefix\"\n",
    "    save_dir: str = \"./samples\"\n",
    ") -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    user_col, time_col = _infer_columns(df, user_col, time_col)\n",
    "    df = _ensure_sorted(df, user_col, time_col)\n",
    "\n",
    "    counts = df.groupby(user_col).size()\n",
    "    need = max(L, (min_stays if min_stays is not None else 0))\n",
    "    sampled_users = _sample_users_with_min_stays(counts, U, need, rng)\n",
    "\n",
    "    pieces = []\n",
    "    for uid in sampled_users:\n",
    "        idx = df.index[df[user_col] == uid].to_numpy()\n",
    "        if slice_mode == \"prefix\":\n",
    "            take_idx = idx[:L]\n",
    "        elif slice_mode == \"random_contiguous\":\n",
    "            take_idx = _random_contiguous_slice(idx, L, rng)\n",
    "        else:\n",
    "            raise ValueError(\"slice_mode must be 'random_contiguous' or 'prefix'\")\n",
    "        pieces.append(df.loc[take_idx])\n",
    "\n",
    "    out = pd.concat(pieces, axis=0)\n",
    "    out = _ensure_sorted(out, user_col, time_col)\n",
    "\n",
    "    filename = f\"geolife_S3_fixedUsers_U{U}_L{L}_seed{random_state}_{slice_mode}.csv\"\n",
    "    _save_df(out, save_dir, filename)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) 一键生成你列举的实验组\n",
    "# -----------------------------\n",
    "def run_all_sampling_grids(\n",
    "    csv_path: str,\n",
    "    save_dir: str = \"./samples\",\n",
    "    random_state: int = 42,\n",
    "    slice_mode: str = \"random_contiguous\"\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): _description_\n",
    "        save_dir (str, optional): _description_. Defaults to \"./samples\".\n",
    "        random_state (int, optional): _description_. Defaults to 42.\n",
    "        slice_mode (str, optional): 当某个用户的原始轨迹长度 > 你需要的长度 L 时，\n",
    "            如何从该用户的轨迹中“截取”样本\n",
    "            slice_mode=\"prefix\"（前缀截取）\n",
    "            slice_mode=\"random_contiguous\"随机选择一个连续长度为 L 的子序列. \n",
    "            Defaults to \"random_contiguous\".\n",
    "    \"\"\"\n",
    "    U_list = [500, 1000, 2000, 4000, 8000, 9900]   # 9.9k\n",
    "    # (1) 固定总样本数 N_total=1M\n",
    "    for U in U_list:\n",
    "        sample_fixed_total_stays(\n",
    "            csv_path=csv_path,\n",
    "            U=U,\n",
    "            N_total=1_000_000,\n",
    "            min_stays=65,\n",
    "            random_state=random_state,\n",
    "            slice_mode=slice_mode,\n",
    "            save_dir=save_dir\n",
    "        )\n",
    "\n",
    "    # (2) 固定每用户长度 L=500\n",
    "    for U in U_list:\n",
    "        sample_fixed_per_user_stays(\n",
    "            csv_path=csv_path,\n",
    "            U=U,\n",
    "            L=500,\n",
    "            random_state=random_state,\n",
    "            slice_mode=slice_mode,\n",
    "            save_dir=save_dir\n",
    "        )\n",
    "\n",
    "    # (3) 固定用户数 U=2000，改变 L\n",
    "    for L in [100, 200, 500, 800, 1000]:\n",
    "        sample_fixed_user_count(\n",
    "            csv_path=csv_path,\n",
    "            U=2000,\n",
    "            L=L,\n",
    "            min_stays=None,  # 如果你想也强制 >=65，可以改成 65\n",
    "            random_state=random_state,\n",
    "            slice_mode=slice_mode,\n",
    "            save_dir=save_dir\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 你上传的数据路径（示例）\n",
    "    # csv_path = \"./Data/Output/all_users_context_combined.csv\"\n",
    "    csv_path = \"./Data/MoreUser/all.csv\"\n",
    "    run_all_sampling_grids(\n",
    "        csv_path=csv_path,\n",
    "        save_dir=\"./Data/MoreUser/Sampled/\",\n",
    "        random_state=42,\n",
    "        slice_mode=\"random_contiguous\"  # 或 \"\"prefix\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728fc48",
   "metadata": {},
   "source": [
    "## 单纯用户数量抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c808db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def sample_user_trajectories(\n",
    "    csv_path,\n",
    "    num_users,\n",
    "    user_col=\"user_id\",\n",
    "    time_col=\"timestamp\",\n",
    "    random_state=42,\n",
    "    save_dir=None,\n",
    "    save_prefix=\"sampled_users\"\n",
    "):\n",
    "    \"\"\"\n",
    "    随机抽样指定数量的用户轨迹，保持单个用户内部顺序不变\n",
    "    若提供 save_dir，则保存结果到文件，文件名包含抽样用户数量\n",
    "    \"\"\"\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(csv_path, index_col=0)\n",
    "\n",
    "    # 获取所有用户\n",
    "    all_users = df[user_col].unique()\n",
    "    if num_users > len(all_users):\n",
    "        raise ValueError(\"抽样用户数量超过数据集中用户总数\")\n",
    "\n",
    "    # 随机抽样用户\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    sampled_users = rng.choice(all_users, size=num_users, replace=False)\n",
    "\n",
    "    # 过滤数据\n",
    "    sampled_df = df[df[user_col].isin(sampled_users)]\n",
    "\n",
    "    # 保证每个用户内部轨迹按时间排序\n",
    "    sampled_df = sampled_df.sort_values(\n",
    "        by=[user_col, time_col]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # 保存结果（如果需要）\n",
    "    if save_dir is not None:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(\n",
    "            save_dir,\n",
    "            f\"{save_prefix}_{num_users}.csv\"\n",
    "        )\n",
    "        sampled_df.to_csv(save_path, index=False)\n",
    "        print(f\"抽样数据已保存至: {save_path}\")\n",
    "\n",
    "    return sampled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7effd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽样数据已保存至: ./Data/MoreUser/Sampled\\MoreUser_sample_10.csv\n",
      "   userID                stime                etime        lon        lat  \\\n",
      "0     280  2024-10-01 00:05:10  2024-10-01 11:26:49  114.02597  30.578440   \n",
      "1     280  2024-10-01 11:52:48  2024-10-01 13:01:43  114.02151  30.575377   \n",
      "2     280  2024-10-01 13:01:43  2024-10-01 16:43:06  114.02597  30.578440   \n",
      "3     280  2024-10-01 17:19:35  2024-10-01 18:06:42  114.02151  30.575377   \n",
      "4     280  2024-10-01 18:19:14  2024-10-01 19:04:05  113.99754  30.583616   \n",
      "\n",
      "   duration    grid                                      context_fuzzy  \\\n",
      "0   40899.0  5220.0                                                NaN   \n",
      "1    4135.0  5118.0  User 280 will move from grid 5118 to grid 5019...   \n",
      "2   13283.0  5220.0  User 280 will move from grid 5220 to grid 4920...   \n",
      "3    2827.0  5118.0                                                NaN   \n",
      "4    2691.0  4920.0                                                NaN   \n",
      "\n",
      "                                     context_precise  \n",
      "0                                                NaN  \n",
      "1  User 280 will move from grid 5118 to grid 5019...  \n",
      "2  User 280 will move from grid 5220 to grid 4920...  \n",
      "3                                                NaN  \n",
      "4                                                NaN  \n",
      "抽样用户数: 10\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # csv_path = \"./Data/Output/all_users_context_combined.csv\"\n",
    "    csv_path = \"./Data/MoreUser/all.csv\"\n",
    "\n",
    "    for num_users in [10, 100, 500, 1000, 2000, 5000, 8000]:\n",
    "\n",
    "        sampled_df = sample_user_trajectories(\n",
    "            csv_path=csv_path,\n",
    "            num_users=num_users,\n",
    "            user_col=\"userID\",\n",
    "            time_col=\"stime\",\n",
    "            save_dir=\"./Data/MoreUser/Sampled\",   # 保存目录\n",
    "            save_prefix=\"MoreUser_sample\"\n",
    "        )\n",
    "\n",
    "        # print(sampled_df.head())\n",
    "        print(f\"抽样用户数: {sampled_df['userID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8833bef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "userID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "duration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "grid",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5bb05906-9091-49c1-89a6-24dcd7edb8c5",
       "rows": [
        [
         "count",
         "6810.0",
         "6810.0",
         "6810.0",
         "6810.0",
         "6810.0",
         "6810.0"
        ],
        [
         "mean",
         "507.91204111600587",
         "4580.372540381792",
         "114.27133661233482",
         "30.655583857415564",
         "20329.751835535975",
         "9061.000440528634"
        ],
        [
         "std",
         "407.74199535901994",
         "3482.1252508452085",
         "0.1466269373679513",
         "0.14337637437879971",
         "57909.18799098625",
         "3000.901607675799"
        ],
        [
         "min",
         "0.0",
         "280.0",
         "113.68186",
         "30.35869",
         "1800.0",
         "0.0"
        ],
        [
         "25%",
         "181.0",
         "487.0",
         "114.23063",
         "30.57737",
         "2980.75",
         "6721.0"
        ],
        [
         "50%",
         "401.0",
         "4921.0",
         "114.29945",
         "30.59836",
         "5904.5",
         "8462.0"
        ],
        [
         "75%",
         "735.0",
         "7920.0",
         "114.36661",
         "30.672186",
         "16425.0",
         "11094.0"
        ],
        [
         "max",
         "1677.0",
         "8681.0",
         "114.89435",
         "31.367685",
         "1575181.0",
         "17600.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userID</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>duration</th>\n",
       "      <th>grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6810.000000</td>\n",
       "      <td>6810.000000</td>\n",
       "      <td>6810.000000</td>\n",
       "      <td>6810.000000</td>\n",
       "      <td>6.810000e+03</td>\n",
       "      <td>6810.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>507.912041</td>\n",
       "      <td>4580.372540</td>\n",
       "      <td>114.271337</td>\n",
       "      <td>30.655584</td>\n",
       "      <td>2.032975e+04</td>\n",
       "      <td>9061.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>407.741995</td>\n",
       "      <td>3482.125251</td>\n",
       "      <td>0.146627</td>\n",
       "      <td>0.143376</td>\n",
       "      <td>5.790919e+04</td>\n",
       "      <td>3000.901608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>113.681860</td>\n",
       "      <td>30.358690</td>\n",
       "      <td>1.800000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>181.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>114.230630</td>\n",
       "      <td>30.577370</td>\n",
       "      <td>2.980750e+03</td>\n",
       "      <td>6721.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>401.000000</td>\n",
       "      <td>4921.000000</td>\n",
       "      <td>114.299450</td>\n",
       "      <td>30.598360</td>\n",
       "      <td>5.904500e+03</td>\n",
       "      <td>8462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>735.000000</td>\n",
       "      <td>7920.000000</td>\n",
       "      <td>114.366610</td>\n",
       "      <td>30.672186</td>\n",
       "      <td>1.642500e+04</td>\n",
       "      <td>11094.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1677.000000</td>\n",
       "      <td>8681.000000</td>\n",
       "      <td>114.894350</td>\n",
       "      <td>31.367685</td>\n",
       "      <td>1.575181e+06</td>\n",
       "      <td>17600.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0       userID          lon          lat      duration  \\\n",
       "count  6810.000000  6810.000000  6810.000000  6810.000000  6.810000e+03   \n",
       "mean    507.912041  4580.372540   114.271337    30.655584  2.032975e+04   \n",
       "std     407.741995  3482.125251     0.146627     0.143376  5.790919e+04   \n",
       "min       0.000000   280.000000   113.681860    30.358690  1.800000e+03   \n",
       "25%     181.000000   487.000000   114.230630    30.577370  2.980750e+03   \n",
       "50%     401.000000  4921.000000   114.299450    30.598360  5.904500e+03   \n",
       "75%     735.000000  7920.000000   114.366610    30.672186  1.642500e+04   \n",
       "max    1677.000000  8681.000000   114.894350    31.367685  1.575181e+06   \n",
       "\n",
       "               grid  \n",
       "count   6810.000000  \n",
       "mean    9061.000441  \n",
       "std     3000.901608  \n",
       "min        0.000000  \n",
       "25%     6721.000000  \n",
       "50%     8462.000000  \n",
       "75%    11094.000000  \n",
       "max    17600.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
