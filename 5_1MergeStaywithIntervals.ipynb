{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c666c098",
   "metadata": {},
   "source": [
    "# 合并样本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5cc32",
   "metadata": {},
   "source": [
    "## 合并gird相同且连续的样本\n",
    "\n",
    "发现数据中有很多样本的时间间隔非常小，同时grid相同，需要进行清洗。\n",
    "\n",
    "对 同一用户 的轨迹，按时间排序后：\n",
    "\n",
    "若满足 同时满足：\n",
    "\n",
    "1. grid_i == grid_{i+1}\n",
    "2. stime_{i+1} - etime_i < 30 minutes\n",
    "\n",
    "则认为是 同一次停留的伪分割，应合并为一条：\n",
    "\n",
    "1. grid：保持不变\n",
    "2. stime ：取第一条的 stime\n",
    "3. etime ：取最后一条的 etime\n",
    "4. duration重新计算，通过合并之后的一条样本的 etime - stime 得到。\n",
    "5. context_fuzzy, context_precise列中如果多个样本都有，那么选择保留第一个样本的内容；如果多个样本中只有一个样本 context_fuzzy, context_precise有值那么保留有值的样本的 context_fuzzy, context_precise；如果都没有那么继续保持为空。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd1c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def _has_value(x) -> bool:\n",
    "    \"\"\"判定 context 是否“有值”：非 NaN 且非空字符串。\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return False\n",
    "    if isinstance(x, str):\n",
    "        return x.strip() != \"\"\n",
    "    return True  # 非字符串（例如 dict/对象）只要非 NaN 就算有值\n",
    "\n",
    "\n",
    "def _merge_context(cur_val, next_val):\n",
    "    \"\"\"\n",
    "    context 合并规则：\n",
    "    - 如果 cur 已有值：永远保留 cur（“多条都有值保留第一条”）\n",
    "    - 如果 cur 没值但 next 有值：用 next（“只有一个有值则保留有值的”）\n",
    "    - 否则保持空\n",
    "    \"\"\"\n",
    "    if _has_value(cur_val):\n",
    "        return cur_val\n",
    "    if _has_value(next_val):\n",
    "        return next_val\n",
    "    return cur_val  # 都空，保持空（可能是 NaN 或 \"\"）\n",
    "\n",
    "\n",
    "def merge_consecutive_stays(\n",
    "    df,\n",
    "    user_col=\"user_id\",\n",
    "    grid_col=\"grid\",\n",
    "    stime_col=\"stime\",\n",
    "    etime_col=\"etime\",\n",
    "    duration_col=\"duration\",\n",
    "    lat_col=\"lat\",\n",
    "    lon_col=\"lon\",\n",
    "    ctx_fuzzy_col=\"context_fuzzy\",\n",
    "    ctx_precise_col=\"context_precise\",\n",
    "    gap_minutes=30,\n",
    "    duration_unit=\"minutes\",  # \"minutes\" or \"seconds\"\n",
    "):\n",
    "    \"\"\"\n",
    "    合并同一用户中相邻 stay：\n",
    "    - grid 相同\n",
    "    - 且 (next.stime - cur.etime) < gap_minutes\n",
    "\n",
    "    合并策略：\n",
    "    - stime: 保留第一个\n",
    "    - etime: 取合并段内最大\n",
    "    - duration: 用 (etime - stime) 重算\n",
    "    - lat/lon: 保留第一个样本的\n",
    "    - context_fuzzy/context_precise:\n",
    "        * 多条都有值 -> 保留第一条\n",
    "        * 只有一条有值 -> 保留有值那条\n",
    "        * 都无值 -> 保持为空\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # datetime\n",
    "    df[stime_col] = pd.to_datetime(df[stime_col])\n",
    "    df[etime_col] = pd.to_datetime(df[etime_col])\n",
    "\n",
    "    # sort\n",
    "    df = df.sort_values([user_col, stime_col]).reset_index(drop=True)\n",
    "\n",
    "    merged_rows = []\n",
    "\n",
    "    for uid, user_df in df.groupby(user_col, sort=False):\n",
    "        user_df = user_df.reset_index(drop=True)\n",
    "        cur_row = user_df.iloc[0].to_dict()\n",
    "\n",
    "        # 记录“段起点”的 lat/lon（实际上 cur_row 初始就已经是第一个）\n",
    "        # 后续合并时不更新 lat/lon，即自然满足“保留第一个样本的 lat/lon”。\n",
    "\n",
    "        for i in range(1, len(user_df)):\n",
    "            next_row = user_df.iloc[i]\n",
    "\n",
    "            same_grid = next_row[grid_col] == cur_row[grid_col]\n",
    "            gap = (next_row[stime_col] - cur_row[etime_col]).total_seconds() / 60\n",
    "\n",
    "            if same_grid and gap < gap_minutes:\n",
    "                # 1) 延长 etime\n",
    "                cur_row[etime_col] = max(cur_row[etime_col], next_row[etime_col])\n",
    "\n",
    "                # 2) lat/lon 保留第一个：啥也不做（不覆盖）\n",
    "\n",
    "                # 3) 合并 context（按规则）\n",
    "                if ctx_fuzzy_col in cur_row and ctx_fuzzy_col in next_row:\n",
    "                    cur_row[ctx_fuzzy_col] = _merge_context(cur_row.get(ctx_fuzzy_col), next_row.get(ctx_fuzzy_col))\n",
    "                if ctx_precise_col in cur_row and ctx_precise_col in next_row:\n",
    "                    cur_row[ctx_precise_col] = _merge_context(cur_row.get(ctx_precise_col), next_row.get(ctx_precise_col))\n",
    "\n",
    "            else:\n",
    "                # 结束当前段：重算 duration\n",
    "                delta_sec = (cur_row[etime_col] - cur_row[stime_col]).total_seconds()\n",
    "                if duration_unit == \"minutes\":\n",
    "                    cur_row[duration_col] = delta_sec / 60.0\n",
    "                elif duration_unit == \"seconds\":\n",
    "                    cur_row[duration_col] = delta_sec\n",
    "                else:\n",
    "                    raise ValueError(\"duration_unit must be 'minutes' or 'seconds'\")\n",
    "\n",
    "                merged_rows.append(cur_row)\n",
    "                cur_row = next_row.to_dict()\n",
    "\n",
    "        # 最后一段\n",
    "        delta_sec = (cur_row[etime_col] - cur_row[stime_col]).total_seconds()\n",
    "        if duration_unit == \"minutes\":\n",
    "            cur_row[duration_col] = delta_sec / 60.0\n",
    "        elif duration_unit == \"seconds\":\n",
    "            cur_row[duration_col] = delta_sec\n",
    "        else:\n",
    "            raise ValueError(\"duration_unit must be 'minutes' or 'seconds'\")\n",
    "\n",
    "        merged_rows.append(cur_row)\n",
    "\n",
    "    merged_df = pd.DataFrame(merged_rows)\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e23551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Data/MoreUser/all.csv\")\n",
    "\n",
    "df_merged = merge_consecutive_stays(\n",
    "    df,\n",
    "    user_col=\"userID\",\n",
    "    grid_col=\"grid\",\n",
    "    stime_col=\"stime\",\n",
    "    etime_col=\"etime\",\n",
    "    duration_col=\"duration\",\n",
    "    lat_col=\"lat\",\n",
    "    lon_col=\"lon\",\n",
    "    ctx_fuzzy_col=\"context_fuzzy\",\n",
    "    ctx_precise_col=\"context_precise\",\n",
    "    gap_minutes=30,\n",
    "    duration_unit=\"seconds\",\n",
    ")\n",
    "\n",
    "df_merged.to_csv(\"./Data/MoreUser/all_merged30min.csv\", index=False)\n",
    "\n",
    "# moreuser consume 23m 10.7s ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63df9d",
   "metadata": {},
   "source": [
    "## 合并gap（时间价格）等于或者约等于0的样本\n",
    "\n",
    "合并规则如下：\n",
    "\n",
    "1. grid：取样本中duration时间最长的。 \n",
    "2. stime ：取第一条的 stime \n",
    "3. etime ：取最后一条的 etime \n",
    "4. duration重新计算，通过合并之后的一条样本的 etime - stime 得到。 \n",
    "5. context_fuzzy, context_precise列中如果多个样本都有，那么选择保留第停留时间最长样本的内容；如果多个样本中只有一个样本包含 context_fuzzy, context_precise就只那么保留有值的样本的 context_fuzzy, context_precise；如果都没有那么继续保持为空。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28694791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def _has_value(x) -> bool:\n",
    "    if pd.isna(x):\n",
    "        return False\n",
    "    if isinstance(x, str):\n",
    "        return x.strip() != \"\"\n",
    "    return True\n",
    "\n",
    "\n",
    "def merge_stays_with_nonpositive_gap(\n",
    "    df,\n",
    "    user_col=\"user_id\",\n",
    "    grid_col=\"grid\",\n",
    "    stime_col=\"stime\",\n",
    "    etime_col=\"etime\",\n",
    "    duration_col=\"duration\",\n",
    "    ctx_fuzzy_col=\"context_fuzzy\",\n",
    "    ctx_precise_col=\"context_precise\",\n",
    "    duration_unit=\"minutes\",   # or \"seconds\"\n",
    "):\n",
    "    df = df.copy()\n",
    "\n",
    "    # datetime\n",
    "    df[stime_col] = pd.to_datetime(df[stime_col])\n",
    "    df[etime_col] = pd.to_datetime(df[etime_col])\n",
    "\n",
    "    # sort\n",
    "    df = df.sort_values([user_col, stime_col]).reset_index(drop=True)\n",
    "\n",
    "    merged_rows = []\n",
    "\n",
    "    for uid, user_df in df.groupby(user_col, sort=False):\n",
    "        user_df = user_df.reset_index(drop=True)\n",
    "\n",
    "        segment = [user_df.iloc[0]]\n",
    "\n",
    "        for i in range(1, len(user_df)):\n",
    "            prev = segment[-1]\n",
    "            curr = user_df.iloc[i]\n",
    "\n",
    "            gap = (curr[stime_col] - prev[etime_col]).total_seconds() / 60.0\n",
    "\n",
    "            if gap <= 0:\n",
    "                # 继续收集到当前 segment\n",
    "                segment.append(curr)\n",
    "            else:\n",
    "                # 处理当前 segment\n",
    "                merged_rows.append(\n",
    "                    _merge_one_segment(\n",
    "                        segment,\n",
    "                        grid_col,\n",
    "                        stime_col,\n",
    "                        etime_col,\n",
    "                        duration_col,\n",
    "                        ctx_fuzzy_col,\n",
    "                        ctx_precise_col,\n",
    "                        duration_unit,\n",
    "                    )\n",
    "                )\n",
    "                segment = [curr]\n",
    "\n",
    "        # 最后一个 segment\n",
    "        merged_rows.append(\n",
    "            _merge_one_segment(\n",
    "                segment,\n",
    "                grid_col,\n",
    "                stime_col,\n",
    "                etime_col,\n",
    "                duration_col,\n",
    "                ctx_fuzzy_col,\n",
    "                ctx_precise_col,\n",
    "                duration_unit,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(merged_rows)\n",
    "\n",
    "\n",
    "def _merge_one_segment(\n",
    "    segment,\n",
    "    grid_col,\n",
    "    stime_col,\n",
    "    etime_col,\n",
    "    duration_col,\n",
    "    ctx_fuzzy_col,\n",
    "    ctx_precise_col,\n",
    "    duration_unit,\n",
    "):\n",
    "    # segment: List[pd.Series]\n",
    "\n",
    "    # 1. stime / etime\n",
    "    stime = segment[0][stime_col]\n",
    "    etime = segment[-1][etime_col]\n",
    "\n",
    "    # 2. duration（重算）\n",
    "    delta_sec = (etime - stime).total_seconds()\n",
    "    duration = delta_sec / 60.0 if duration_unit == \"minutes\" else delta_sec\n",
    "\n",
    "    # 3. 选 duration 最长的原始 stay\n",
    "    longest = max(\n",
    "        segment,\n",
    "        key=lambda r: (\n",
    "            r[duration_col]\n",
    "            if pd.notna(r[duration_col])\n",
    "            else -1\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # 4. grid\n",
    "    grid = longest[grid_col]\n",
    "\n",
    "    # 5. context（按“最长 duration 优先”）\n",
    "    def pick_context(col):\n",
    "        candidates = [r for r in segment if _has_value(r[col])]\n",
    "        if not candidates:\n",
    "            return None\n",
    "        if len(candidates) == 1:\n",
    "            return candidates[0][col]\n",
    "        return max(\n",
    "            candidates,\n",
    "            key=lambda r: r[duration_col] if pd.notna(r[duration_col]) else -1,\n",
    "        )[col]\n",
    "\n",
    "    ctx_fuzzy = pick_context(ctx_fuzzy_col)\n",
    "    ctx_precise = pick_context(ctx_precise_col)\n",
    "\n",
    "    # 6. 输出行（以第一条为模板）\n",
    "    out = segment[0].to_dict()\n",
    "    out[stime_col] = stime\n",
    "    out[etime_col] = etime\n",
    "    out[duration_col] = duration\n",
    "    out[grid_col] = grid\n",
    "    out[ctx_fuzzy_col] = ctx_fuzzy\n",
    "    out[ctx_precise_col] = ctx_precise\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4104afe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 5147648\n",
      "After : 3007840\n",
      "Saved : ./Data/MoreUser/all_gapLE0_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) 读入数据\n",
    "df = pd.read_csv(\"./Data/MoreUser/all_merged30min.csv\")\n",
    "\n",
    "# 2) 合并 gap <= 0 的 stay（按你制定的规则）\n",
    "df_merged = merge_stays_with_nonpositive_gap(\n",
    "    df,\n",
    "    user_col=\"userID\",\n",
    "    grid_col=\"grid\",\n",
    "    stime_col=\"stime\",\n",
    "    etime_col=\"etime\",\n",
    "    duration_col=\"duration\",\n",
    "    ctx_fuzzy_col=\"context_fuzzy\",\n",
    "    ctx_precise_col=\"context_precise\",\n",
    "    duration_unit=\"seconds\",   # 如果你的 duration 是秒，改成 \"seconds\"\n",
    ")\n",
    "\n",
    "# 3) 保存\n",
    "out_path = \"./Data/MoreUser/all_gapLE0_merged.csv\"\n",
    "df_merged.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Before:\", len(df))\n",
    "print(\"After :\", len(df_merged))\n",
    "print(\"Saved :\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
